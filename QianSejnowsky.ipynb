{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Libraries and Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing necessary libraries\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Input, LSTM, Dense\n",
    "from sklearn.metrics import matthews_corrcoef\n",
    "\n",
    "# Function definitions\n",
    "\n",
    "def parse_data(file_path):\n",
    "    sequences, secondary_structures = [], []\n",
    "    parsing_sequences = False\n",
    "    with open(file_path, \"r\") as file:\n",
    "        for line in file:\n",
    "            line = line.strip()\n",
    "            if line == \"<>\":\n",
    "                parsing_sequences = True\n",
    "            elif line == \"end\":\n",
    "                parsing_sequences = False\n",
    "            elif parsing_sequences:\n",
    "                parts = line.split()\n",
    "                if len(parts) == 2:\n",
    "                    amino_acid, sec_structure = parts\n",
    "                    sequences.append(amino_acid)\n",
    "                    secondary_structures.append(sec_structure)\n",
    "    return sequences, secondary_structures\n",
    "\n",
    "def create_windows(sequences, secondary_structures, window_size=13):\n",
    "    X, y = [], []\n",
    "    padded_sequences = ['_' for _ in range(window_size // 2)] + sequences + ['_' for _ in range(window_size // 2)]\n",
    "    for i in range(len(sequences)):\n",
    "        window = padded_sequences[i:i + window_size]\n",
    "        X.append(window)\n",
    "        y.append(secondary_structures[i])\n",
    "    return X, y\n",
    "\n",
    "def one_hot_encode(sequence):\n",
    "    amino_acids = 'ACDEFGHIKLMNPQRSTVWY'\n",
    "    num_amino_acids = len(amino_acids)\n",
    "    encoded_seq = np.zeros((len(sequence), num_amino_acids), dtype=int)\n",
    "    for i, aa in enumerate(sequence):\n",
    "        if aa in amino_acids:\n",
    "            encoded_seq[i, amino_acids.index(aa)] = 1\n",
    "    return encoded_seq\n",
    "\n",
    "def encode_labels(labels):\n",
    "    encoding = {'_': 0, 'e': 1, 'h': 2}\n",
    "    encoded_labels = np.array([encoding[label] for label in labels])\n",
    "    return encoded_labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read and parse the data\n",
    "train_path = 'Q_and_s_data/protein-secondary-structure.train.txt'\n",
    "test_path = 'Q_and_s_data/protein-secondary-structure.test.txt'\n",
    "\n",
    "X_train, y_train = parse_data(train_path)\n",
    "X_test, y_test = parse_data(test_path)\n",
    "\n",
    "# Create sliding windows\n",
    "window_size = 13\n",
    "X_train_windows, y_train_windows = create_windows(X_train, y_train, window_size)\n",
    "X_test_windows, y_test_windows = create_windows(X_test, y_test, window_size)\n",
    "\n",
    "# Encode sequences and labels\n",
    "X_train_encoded = np.array([one_hot_encode(sequence) for sequence in X_train_windows])\n",
    "y_train_encoded = encode_labels(y_train_windows)\n",
    "\n",
    "X_test_encoded = np.array([one_hot_encode(sequence) for sequence in X_test_windows])\n",
    "y_test_encoded = encode_labels(y_test_windows)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model training and evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/12\n",
      "\u001b[1m566/566\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.5520 - loss: 0.9428\n",
      "Epoch 2/12\n",
      "\u001b[1m566/566\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.6167 - loss: 0.8447\n",
      "Epoch 3/12\n",
      "\u001b[1m566/566\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.6312 - loss: 0.8093\n",
      "Epoch 4/12\n",
      "\u001b[1m566/566\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.6421 - loss: 0.7891\n",
      "Epoch 5/12\n",
      "\u001b[1m566/566\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.6525 - loss: 0.7772\n",
      "Epoch 6/12\n",
      "\u001b[1m566/566\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.6621 - loss: 0.7632\n",
      "Epoch 7/12\n",
      "\u001b[1m566/566\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.6596 - loss: 0.7515\n",
      "Epoch 8/12\n",
      "\u001b[1m566/566\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.6744 - loss: 0.7299\n",
      "Epoch 9/12\n",
      "\u001b[1m566/566\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.6942 - loss: 0.7064\n",
      "Epoch 10/12\n",
      "\u001b[1m566/566\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7025 - loss: 0.6826\n",
      "Epoch 11/12\n",
      "\u001b[1m566/566\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7141 - loss: 0.6579\n",
      "Epoch 12/12\n",
      "\u001b[1m566/566\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7216 - loss: 0.6488\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 908us/step - accuracy: 0.6045 - loss: 0.9129\n",
      "Test Loss: 0.9383350610733032, Test Accuracy: 0.6105113625526428\n"
     ]
    }
   ],
   "source": [
    "# Define and compile the model\n",
    "model = Sequential([\n",
    "    Input(shape=(window_size, 20)),\n",
    "    LSTM(units=40),\n",
    "    Dense(units=3, activation='softmax')\n",
    "])\n",
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train_encoded, y_train_encoded, epochs=12, batch_size=32)\n",
    "\n",
    "# Evaluate the model\n",
    "loss, accuracy = model.evaluate(X_test_encoded, y_test_encoded)\n",
    "print(f'Test Loss: {loss}, Test Accuracy: {accuracy}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prediction and evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step\n",
      "Q3: 0.6105113636363636\n"
     ]
    }
   ],
   "source": [
    "# Predict and evaluate secondary structures\n",
    "y_pred_prob = model.predict(X_test_encoded)\n",
    "y_pred_labels = np.argmax(y_pred_prob, axis=1)\n",
    "\n",
    "# Calculate Q3 measure\n",
    "correct_predictions = np.sum(y_pred_labels == y_test_encoded)\n",
    "total_predictions = len(y_test_encoded)\n",
    "Q3 = correct_predictions / total_predictions\n",
    "print(\"Q3:\", Q3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MCC for class coil: 0.3567052946313261\n",
      "MCC for class β-sheet: 0.2848761866234614\n",
      "MCC for class α-helix: 0.30678549626819807\n"
     ]
    }
   ],
   "source": [
    "# Matthews correlation coefficient calculation\n",
    "\n",
    "# Calculate Matthews correlation coefficient\n",
    "class_names = {0: 'coil', 1: 'β-sheet', 2: 'α-helix'}\n",
    "correlation_coefficients = {}\n",
    "for class_idx in range(3):\n",
    "    actual_labels = (y_test_encoded == class_idx).astype(int)\n",
    "    predicted_labels = (y_pred_labels == class_idx).astype(int)\n",
    "    correlation_coefficient = matthews_corrcoef(actual_labels, predicted_labels)\n",
    "    correlation_coefficients[class_names[class_idx]] = correlation_coefficient\n",
    "\n",
    "# Print correlation coefficients\n",
    "for class_name, correlation_coefficient in correlation_coefficients.items():\n",
    "    print(f\"MCC for class {class_name}: {correlation_coefficient}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1 net:\n",
    "    Q3 - 62.7%\n",
    "    Cα - 0.35\n",
    "    Cβ - 0.29\n",
    "    Cc - 0.38\n",
    "    \n",
    "2 nets:\n",
    "    Q3 - 64.3%\n",
    "    Cα - 0.41\n",
    "    Cβ - 0.31\n",
    "    Cc - 0.41\n",
    "\n",
    "Mine:\n",
    "    Q3 - 61.1%\n",
    "    Cα - 0.36\n",
    "    Cβ - 0.28\n",
    "    Cc - 0.31"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
