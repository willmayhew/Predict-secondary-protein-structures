{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Libraries and Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 338,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Input, LSTM, Dense, Flatten, Conv1D, Conv2D, Dropout, BatchNormalization, MaxPooling1D\n",
    "from keras.callbacks import EarlyStopping\n",
    "import tensorflow as tf\n",
    "from sklearn.metrics import matthews_corrcoef\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from tensorflow.keras.initializers import Constant\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score\n",
    "import math\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 339,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_data(file_path):\n",
    "    sequences, secondary_structures = [], []\n",
    "    parsing_sequences = False\n",
    "    with open(file_path, \"r\") as file:\n",
    "        sequence = \"\"\n",
    "        secondary_structure = \"\"\n",
    "        for line in file:\n",
    "            line = line.strip()\n",
    "            if line == \"<>\" and not parsing_sequences:\n",
    "                parsing_sequences = True\n",
    "            elif line == \"end\" or line == \"<end>\":\n",
    "                parsing_sequences = False\n",
    "                sequence += \"!\"\n",
    "                sequences.append(sequence)\n",
    "                secondary_structures.append(secondary_structure)\n",
    "                sequence = \"\"\n",
    "                secondary_structure = \"\"\n",
    "            elif parsing_sequences and line == \"<>\":\n",
    "                sequences.append(sequence)\n",
    "                secondary_structures.append(secondary_structure)\n",
    "                sequence = \"\"\n",
    "                secondary_structure = \"\"\n",
    "            elif parsing_sequences:\n",
    "                parts = line.split()\n",
    "                if len(parts) == 2:\n",
    "                    amino_acid, sec_structure = parts\n",
    "                    sequence += amino_acid\n",
    "                    secondary_structure += sec_structure\n",
    "    return sequences, secondary_structures\n",
    "\n",
    "def parse_data_2(file_path):\n",
    "    sequences, secondary_structures = [], []\n",
    "    parsing_sequences = False\n",
    "    with open(file_path, \"r\") as file:\n",
    "        for line in file:\n",
    "            line = line.strip()\n",
    "            if line == \"<>\":\n",
    "                parsing_sequences = True\n",
    "            elif line == \"end\":\n",
    "                parsing_sequences = False\n",
    "            elif parsing_sequences:\n",
    "                parts = line.split()\n",
    "                if len(parts) == 2:\n",
    "                    amino_acid, sec_structure = parts\n",
    "                    sequences.append(amino_acid)\n",
    "                    secondary_structures.append(sec_structure)\n",
    "    return sequences, secondary_structures\n",
    "\n",
    "# Function to read aligned sequences from a file\n",
    "def read_aligned_sequences(file_path):\n",
    "    sequences = {}\n",
    "    with open(file_path, \"r\") as file:\n",
    "        sequence_number = None\n",
    "        sequence = \"\"\n",
    "        for line in file:\n",
    "            line = line.strip()\n",
    "            if line.startswith(\">\"):\n",
    "                if sequence_number is not None:\n",
    "                    sequences[sequence_number] = sequence\n",
    "                sequence_number = int(line.split(\"_\")[1])\n",
    "                sequence = \"\"\n",
    "            else:\n",
    "                sequence += line\n",
    "        if sequence_number is not None and sequence:\n",
    "            sequences[sequence_number] = sequence\n",
    "    return sequences\n",
    "\n",
    "# Function to align structures with sequences\n",
    "def align_structure(structures, sequences):\n",
    "    aligned = {}\n",
    "    for i in sequences.keys():\n",
    "        align = []\n",
    "        sequence = sequences[i]\n",
    "        structure = structures[i-1]\n",
    "\n",
    "        j = 0\n",
    "        for char in sequence:\n",
    "            if char == '-':\n",
    "                align.append('-')\n",
    "            else:\n",
    "                align.append(structure[j])\n",
    "                j += 1\n",
    "        aligned[i] = align\n",
    "    return aligned\n",
    "\n",
    "# Function to encode a sequence using one-hot encoding\n",
    "# def encode_sequence(sequence):\n",
    "#     amino_acids = 'ACDEFGHIKLMNPQRSTVWY!'\n",
    "#     num_amino_acids = len(amino_acids)\n",
    "#     encoded_seq = np.zeros((len(sequence), num_amino_acids), dtype=int)\n",
    "#     for i, aa in enumerate(sequence):\n",
    "#         if aa in amino_acids:\n",
    "#             encoded_seq[i, amino_acids.index(aa)] = 1\n",
    "#     return encoded_seq\n",
    "\n",
    "# Function to encode a structure\n",
    "def encode_structure(structure):\n",
    "    mapping = {'-': 3, '_': 0, 'e': 1, 'h': 2}\n",
    "    return [mapping[char] for char in structure]\n",
    "\n",
    "def calculate_accuracy(y_true, y_pred):\n",
    "\n",
    "    if len(y_pred.shape) == 2:\n",
    "        y_pred_labels = np.argmax(y_pred, axis=1)\n",
    "    else:\n",
    "        y_pred_labels = y_pred\n",
    "\n",
    "    class_accuracies = {}\n",
    "    for class_idx in range(3):\n",
    "        class_pred_labels = y_pred_labels[y_true == class_idx]\n",
    "        class_true_labels = y_true[y_true == class_idx]\n",
    "\n",
    "        class_accuracy = np.sum(class_pred_labels == class_true_labels) / len(class_true_labels)\n",
    "\n",
    "        # class_names = {0: 'coil', 1: 'β-sheet', 2: 'α-helix'}\n",
    "        class_accuracies[class_idx] = class_accuracy\n",
    "\n",
    "    # for class_name, accuracy in class_accuracies.items():\n",
    "    #     print(f\"Accuracy for class {class_name}: {accuracy}\")\n",
    "\n",
    "    total_correct_predictions = np.sum(y_pred_labels == y_true)\n",
    "    total_accuracy = total_correct_predictions / len(y_true)\n",
    "\n",
    "    # print(\"Total Accuracy:\", total_accuracy)\n",
    "\n",
    "    return total_accuracy, class_accuracies\n",
    "\n",
    "def preprocess_data(aligned_sequences, aligned_sequence_structures, pssm, window_size):\n",
    "    X = []\n",
    "    y = []\n",
    "\n",
    "    for seq_id, sequence in aligned_sequences.items():\n",
    "        encoded_seq = encode_sequence_new(sequence, pssm)\n",
    "        encoded_struct = encode_structure(aligned_sequence_structures[seq_id])\n",
    "\n",
    "        # Pad the sequence symmetrically around each position\n",
    "        pad_width = ((window_size // 2, window_size // 2), (0, 0))\n",
    "        padded_seq = np.pad(encoded_seq, pad_width, mode='constant')\n",
    "\n",
    "        for i in range(len(sequence)):\n",
    "            # Extract window_size elements centered around the current position\n",
    "            window_start = i\n",
    "            window_end = i + window_size\n",
    "            window = padded_seq[window_start:window_end]\n",
    "\n",
    "            X.append(window)\n",
    "            y.append(encoded_struct[i])\n",
    "\n",
    "    # Remove instances with padding\n",
    "    for i in range(len(y) - 1, -1, -1):\n",
    "        if y[i] == 3:\n",
    "            X.pop(i)\n",
    "            y.pop(i)\n",
    "\n",
    "    return np.array(X), np.array(y)\n",
    "\n",
    "def encode_sequence_new(sequence, pssm):\n",
    "    amino_acids = 'ACDEFGHIKLMNPQRSTVWY'\n",
    "    num_amino_acids = len(amino_acids)\n",
    "    encoded_seq = np.zeros((len(sequence), num_amino_acids), dtype=float)\n",
    "    for i, aa in enumerate(sequence):\n",
    "        if aa != \"-\":\n",
    "        # for j, a in enumerate(amino_acids):\n",
    "        #     encoded_seq[i, j] = pssm[i][a]\n",
    "            # encoded_seq[i, amino_acids.index(aa)] = pssm[i][aa]\n",
    "            encoded_seq[i, amino_acids.index(aa)] = 1\n",
    "    return encoded_seq\n",
    "\n",
    "def create_windows(sequences, secondary_structures, window_size=13):\n",
    "    X, y = [], []\n",
    "    padded_sequences = ['_' for _ in range(window_size // 2)] + sequences + ['_' for _ in range(window_size // 2)]\n",
    "    for i in range(len(sequences)):\n",
    "        window = padded_sequences[i:i + window_size]\n",
    "        X.append(window)\n",
    "        y.append(secondary_structures[i])\n",
    "    return X, y\n",
    "\n",
    "def create_windows_new(sequences, window_size):\n",
    "    num_samples, num_features = sequences.shape\n",
    "    padded_seq = np.zeros((num_samples, window_size, num_features))\n",
    "    pad_size = window_size // 2\n",
    "\n",
    "    for i in range(num_samples):\n",
    "        start_index = max(0, i - pad_size)\n",
    "        end_index = min(num_samples, i + pad_size + 1)\n",
    "        \n",
    "        # Calculate the indices for the windowed data\n",
    "        window_start = pad_size - (i - start_index)\n",
    "        window_end = window_start + (end_index - start_index)\n",
    "        \n",
    "        # Copy the data into the padded array\n",
    "        padded_seq[i, window_start:window_end, :] = sequences[start_index:end_index, :]\n",
    "    \n",
    "    return padded_seq\n",
    "\n",
    "def preprocess_data_2(predictions, window_size):\n",
    "    sequence_length, num_classes = predictions.shape\n",
    "    pad_width = ((window_size // 2, window_size // 2), (0, 0))\n",
    "\n",
    "    # Define windowed_predictions shape considering all windows\n",
    "    windowed_predictions = np.empty((sequence_length, window_size, num_classes))\n",
    "\n",
    "    # Pad predictions\n",
    "    padded_predictions = np.pad(predictions, pad_width, mode='constant')\n",
    "\n",
    "    # Collect windows into a temporary list (optional)\n",
    "    windows = []\n",
    "    for j in range(len(padded_predictions) - window_size + 1):\n",
    "        window_start = j\n",
    "        window_end = j + window_size\n",
    "        window = padded_predictions[window_start:window_end]\n",
    "        windows.append(window)\n",
    "\n",
    "    # Convert windows list to NumPy array and assign to windowed_predictions\n",
    "    windowed_predictions = np.array(windows)\n",
    "\n",
    "    return windowed_predictions\n",
    "\n",
    "def preprocess_labels(predictions, window_size):\n",
    "    num_samples = predictions.shape[0]\n",
    "    num_classes = 1  # Since predictions is 1D, we have only 1 class\n",
    "    pad_width = ((window_size // 2, window_size // 2), (0, 0))\n",
    "\n",
    "    # Define windowed_predictions shape considering all windows\n",
    "    windowed_predictions = np.empty((num_samples, window_size, num_classes))\n",
    "\n",
    "    # Pad predictions\n",
    "    padded_predictions = np.pad(predictions[:, None], pad_width, mode='constant')\n",
    "\n",
    "    # Collect windows into windowed_predictions directly\n",
    "    for i in range(num_samples):\n",
    "        window_start = i\n",
    "        window_end = i + window_size\n",
    "        windowed_predictions[i] = padded_predictions[window_start:window_end]\n",
    "\n",
    "    return windowed_predictions\n",
    "\n",
    "def calculate_correlation_coefficients(y_test, test_result):\n",
    "    class_names = {0: 'coil', 1: 'β-sheet', 2: 'α-helix'}\n",
    "    correlation_coefficients = {}\n",
    "    for class_idx in range(3):\n",
    "        actual_labels = (y_test == class_idx).astype(int)\n",
    "        predicted_labels = (test_result == class_idx).astype(int)\n",
    "        correlation_coefficient = matthews_corrcoef(actual_labels, predicted_labels)\n",
    "        correlation_coefficients[class_names[class_idx]] = correlation_coefficient\n",
    "\n",
    "    # Print correlation coefficients\n",
    "    for class_name, correlation_coefficient in correlation_coefficients.items():\n",
    "        print(f\"MCC for class {class_name}: {correlation_coefficient}\")\n",
    "\n",
    "\n",
    "def calculate_pssm(aligned_sequences):\n",
    "    pssm = {}\n",
    "    sequence_length = len(list(aligned_sequences.values())[0])\n",
    "    total_sequences = len(aligned_sequences)\n",
    "\n",
    "    # Initialize counts for each position\n",
    "    for i in range(sequence_length):\n",
    "        pssm[i] = {'A': 0, 'C': 0, 'D': 0, 'E': 0, 'F': 0, 'G': 0, 'H': 0, 'I': 0, 'K': 0, 'L': 0,\n",
    "                   'M': 0, 'N': 0, 'P': 0, 'Q': 0, 'R': 0, 'S': 0, 'T': 0, 'V': 0, 'W': 0, 'Y': 0, '-': 0}\n",
    "\n",
    "    # Count occurrences of each amino acid at each position\n",
    "    for sequence in aligned_sequences.values():\n",
    "        for i, aa in enumerate(sequence):\n",
    "            if aa != \"-\":\n",
    "                pssm[i][aa] += 1\n",
    "                \n",
    "    # Normalize counts to frequencies and calculate background frequencies\n",
    "    background_frequencies = {aa: 0 for aa in pssm[0].keys()}\n",
    "    for i in range(sequence_length):\n",
    "        total_count = sum(pssm[i].values())\n",
    "        for aa in pssm[i]:\n",
    "            if total_count != 0:\n",
    "                pssm[i][aa] /= total_count\n",
    "            background_frequencies[aa] += pssm[i][aa] / total_sequences\n",
    "\n",
    "    # Calculate log-odds scores\n",
    "    for i in range(sequence_length):\n",
    "        for aa in pssm[i]:\n",
    "            if background_frequencies[aa] != 0:\n",
    "                ratio = pssm[i][aa] / background_frequencies[aa]\n",
    "                if ratio != 0:\n",
    "                    pssm[i][aa] = math.log2(ratio)\n",
    "\n",
    "    return pssm\n",
    "\n",
    "def plot_history(history):\n",
    "    # Plot training & validation accuracy values\n",
    "    plt.plot(history.history['accuracy'])\n",
    "    plt.plot(history.history['val_accuracy'])\n",
    "    plt.title('Model accuracy')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.legend(['Train', 'Validation'], loc='upper left')\n",
    "    plt.show()\n",
    "\n",
    "    # Plot training & validation loss values\n",
    "    plt.plot(history.history['loss'])\n",
    "    plt.plot(history.history['val_loss'])\n",
    "    plt.title('Model loss')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.legend(['Train', 'Validation'], loc='upper left')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data processing\n",
    "Training and test files are preprocessed into different window sizes and profiled using a position-specific score matrices (pssm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 340,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_path = 'Q_and_s_data/protein-secondary-structure.train.txt'\n",
    "train_sequences, train_structures = parse_data(train_path)\n",
    "aligned_sequences = read_aligned_sequences(\"Fasta_and_msa/training_msa.txt\")\n",
    "aligned_sequence_structures = align_structure(train_structures, aligned_sequences)\n",
    "pssm_train = calculate_pssm(aligned_sequences)\n",
    "\n",
    "test_path = 'Q_and_s_data/protein-secondary-structure.test.txt'\n",
    "test_sequences, test_structures = parse_data(test_path)\n",
    "test_aligned_sequences = read_aligned_sequences(\"Fasta_and_msa/test_msa.txt\")\n",
    "test_aligned_sequence_structures = align_structure(test_structures, test_aligned_sequences)\n",
    "pssm_test = calculate_pssm(test_aligned_sequences)\n",
    "\n",
    "X_train_13, y_train = preprocess_data(aligned_sequences, aligned_sequence_structures, pssm_train, 13)\n",
    "X_train_11, y_train = preprocess_data(aligned_sequences, aligned_sequence_structures, pssm_train, 11)\n",
    "X_train_9, y_train = preprocess_data(aligned_sequences, aligned_sequence_structures, pssm_train, 9)\n",
    "X_train_7, y_train = preprocess_data(aligned_sequences, aligned_sequence_structures, pssm_train, 7)\n",
    "X_train_5, y_train = preprocess_data(aligned_sequences, aligned_sequence_structures, pssm_train, 5)\n",
    "\n",
    "X_test_13, y_test = preprocess_data(test_aligned_sequences, test_aligned_sequence_structures, pssm_test, 13)\n",
    "X_test_11, y_test = preprocess_data(test_aligned_sequences, test_aligned_sequence_structures, pssm_test, 11)\n",
    "X_test_9, y_test = preprocess_data(test_aligned_sequences, test_aligned_sequence_structures, pssm_test, 9)\n",
    "X_test_7, y_test = preprocess_data(test_aligned_sequences, test_aligned_sequence_structures, pssm_test, 7)\n",
    "X_test_5, y_test = preprocess_data(test_aligned_sequences, test_aligned_sequence_structures, pssm_test, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 341,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For window size 13\n",
    "middle = X_train_13.shape[1] // 2\n",
    "new_train = X_train_13[:, middle, :]\n",
    "X_train_13 = create_windows_new(new_train, 13)\n",
    "\n",
    "middle = X_test_13.shape[1] // 2\n",
    "new_test = X_test_13[:, middle, :]\n",
    "X_test_13 = create_windows_new(new_test, 13)\n",
    "\n",
    "# For window size 11\n",
    "middle = X_train_11.shape[1] // 2\n",
    "new_train_11 = X_train_11[:, middle, :]\n",
    "X_train_11 = create_windows_new(new_train_11, 11)\n",
    "\n",
    "middle = X_test_11.shape[1] // 2\n",
    "new_test_11 = X_test_11[:, middle, :]\n",
    "X_test_11 = create_windows_new(new_test_11, 11)\n",
    "\n",
    "# For window size 9\n",
    "middle = X_train_9.shape[1] // 2\n",
    "new_train_9 = X_train_9[:, middle, :]\n",
    "X_train_9 = create_windows_new(new_train_9, 9)\n",
    "\n",
    "middle = X_test_9.shape[1] // 2\n",
    "new_test_9 = X_test_9[:, middle, :]\n",
    "X_test_9 = create_windows_new(new_test_9, 9)\n",
    "\n",
    "# For window size 7\n",
    "middle = X_train_7.shape[1] // 2\n",
    "new_train_7 = X_train_7[:, middle, :]\n",
    "X_train_7 = create_windows_new(new_train_7, 7)\n",
    "\n",
    "middle = X_test_7.shape[1] // 2\n",
    "new_test_7 = X_test_7[:, middle, :]\n",
    "X_test_7 = create_windows_new(new_test_7, 7)\n",
    "\n",
    "# For window size 5\n",
    "middle = X_train_5.shape[1] // 2\n",
    "new_train_5 = X_train_5[:, middle, :]\n",
    "X_train_5 = create_windows_new(new_train_5, 5)\n",
    "\n",
    "middle = X_test_5.shape[1] // 2\n",
    "new_test_5 = X_test_5[:, middle, :]\n",
    "X_test_5 = create_windows_new(new_test_5, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 342,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_sequences, train_structures = parse_data_2(train_path)\n",
    "# x13, y = create_windows(train_sequences, train_structures, 13)\n",
    "# x11, y = create_windows(train_sequences, train_structures, 11)\n",
    "# x9, y = create_windows(train_sequences, train_structures, 9)\n",
    "# x7, y = create_windows(train_sequences, train_structures, 7)\n",
    "# x5, y = create_windows(train_sequences, train_structures, 5)\n",
    "\n",
    "# X_train_13 = np.array([encode_sequence(sequence) for sequence in x13])\n",
    "# X_train_11 = np.array([encode_sequence(sequence) for sequence in x11])\n",
    "# X_train_9 = np.array([encode_sequence(sequence) for sequence in x9])\n",
    "# X_train_7 = np.array([encode_sequence(sequence) for sequence in x7])\n",
    "# X_train_5 = np.array([encode_sequence(sequence) for sequence in x5])\n",
    "# y_train = np.array(encode_structure(y))\n",
    "\n",
    "# test_sequences, test_structures = parse_data_2(test_path)\n",
    "# x13t, yt = create_windows(test_sequences, test_structures, 13)\n",
    "# x11t, yt = create_windows(test_sequences, test_structures, 11)\n",
    "# x9t, yt = create_windows(test_sequences, test_structures, 9)\n",
    "# x7t, yt = create_windows(test_sequences, test_structures, 7)\n",
    "# x5t, yt = create_windows(test_sequences, test_structures, 5)\n",
    "\n",
    "# X_test_13 = np.array([encode_sequence(sequence) for sequence in x13t])\n",
    "# X_test_11 = np.array([encode_sequence(sequence) for sequence in x11t])\n",
    "# X_test_9 = np.array([encode_sequence(sequence) for sequence in x9t])\n",
    "# X_test_7 = np.array([encode_sequence(sequence) for sequence in x7t])\n",
    "# X_test_5 = np.array([encode_sequence(sequence) for sequence in x5t])\n",
    "# y_test = np.array(encode_structure(yt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 343,
   "metadata": {},
   "outputs": [],
   "source": [
    "def replace_values(array, keep_values, replace_value):\n",
    "    mask = np.isin(array, keep_values)\n",
    "    new_array = np.where(mask, 1, replace_value)\n",
    "    return new_array\n",
    "\n",
    "def replace_values_multiple(array, replacements):\n",
    "    masks = [np.isin(array, values) for values in replacements.keys()]\n",
    "    combined_mask = np.any(masks, axis=0)\n",
    "    new_array = np.where(combined_mask, array, -1)\n",
    "    for value, replacement in replacements.items():\n",
    "        new_array = np.where(array == value, replacement, new_array)\n",
    "    \n",
    "    return new_array\n",
    "\n",
    "# h = 2, e = 1, _ or e = 0\n",
    "h_not_h = replace_values(y_train, 2, -1)\n",
    "e_not_e = replace_values(y_train, 1, -1)\n",
    "c_not_c = replace_values(y_train, 0, -1)\n",
    "h_not_e = replace_values_multiple(y_train, {0: 0, 1: -1, 2: 1})\n",
    "e_not_c = replace_values_multiple(y_train, {0: -1, 1: 1, 2: 0})\n",
    "c_not_h = replace_values_multiple(y_train, {0: 1, 1: 0, 2: -1})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 344,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define class weights for each SVM\n",
    "class_weights_hh = compute_class_weight(class_weight='balanced', classes=np.unique(h_not_h), y=h_not_h)\n",
    "weights_hh = dict(zip(np.unique(h_not_h), class_weights_hh))\n",
    "\n",
    "class_weights_ee = compute_class_weight(class_weight='balanced', classes=np.unique(e_not_e), y=e_not_e)\n",
    "weights_ee = dict(zip(np.unique(e_not_e), class_weights_ee))\n",
    "\n",
    "class_weights_cc = compute_class_weight(class_weight='balanced', classes=np.unique(c_not_c), y=c_not_c)\n",
    "weights_cc = dict(zip(np.unique(c_not_c), class_weights_cc))\n",
    "\n",
    "class_weights_he = compute_class_weight(class_weight='balanced', classes=np.unique(h_not_e), y=h_not_e)\n",
    "weights_he = dict(zip(np.unique(h_not_e), class_weights_he))\n",
    "\n",
    "class_weights_ec = compute_class_weight(class_weight='balanced', classes=np.unique(e_not_c), y=e_not_c)\n",
    "weights_ec = dict(zip(np.unique(e_not_c), class_weights_ec))\n",
    "\n",
    "class_weights_ch = compute_class_weight(class_weight='balanced', classes=np.unique(c_not_h), y=c_not_h)\n",
    "weights_ch = dict(zip(np.unique(c_not_h), class_weights_ch))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 345,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_13_reshaped = X_train_13.reshape(X_train_13.shape[0], -1)\n",
    "\n",
    "X_train_11_reshaped = X_train_11.reshape(X_train_11.shape[0], -1)\n",
    "X_train_9_reshaped = X_train_9.reshape(X_train_9.shape[0], -1)\n",
    "X_train_7_reshaped = X_train_7.reshape(X_train_7.shape[0], -1)\n",
    "X_train_5_reshaped = X_train_5.reshape(X_train_5.shape[0], -1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model training and evaluation\n",
    "6 binary SVM classifiers are trained as well as a convolutional neural network (CNN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 346,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM]"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-8 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: black;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-8 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-8 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-8 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-8 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-8 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-8 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-8 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-8 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-8 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-8 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-8 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-8 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-8 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-8 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-8 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: block;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "#sk-container-id-8 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"▸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-8 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-8 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-8 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-8 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-8 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-8 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-8 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"▾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-8 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-8 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-8 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-8 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-8 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-8 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-8 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-8 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-8 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-8 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-8 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-8 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-8 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-8 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 1ex;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-8 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-8 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-8 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-8 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-8\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>SVC(C=1.5,\n",
       "    class_weight={-1: 1.3116713757878722, 0: 1.6597909790979097,\n",
       "                  1: 0.6115727604377786},\n",
       "    verbose=True)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-8\" type=\"checkbox\" checked><label for=\"sk-estimator-id-8\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;&nbsp;SVC<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.4/modules/generated/sklearn.svm.SVC.html\">?<span>Documentation for SVC</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></label><div class=\"sk-toggleable__content fitted\"><pre>SVC(C=1.5,\n",
       "    class_weight={-1: 1.3116713757878722, 0: 1.6597909790979097,\n",
       "                  1: 0.6115727604377786},\n",
       "    verbose=True)</pre></div> </div></div></div></div>"
      ],
      "text/plain": [
       "SVC(C=1.5,\n",
       "    class_weight={-1: 1.3116713757878722, 0: 1.6597909790979097,\n",
       "                  1: 0.6115727604377786},\n",
       "    verbose=True)"
      ]
     },
     "execution_count": 346,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# One-vs-Rest SVM classifiers for each pair of classes\n",
    "svm_h_h = SVC(kernel='rbf', verbose=True, C=1.5, class_weight=weights_hh)\n",
    "svm_e_e = SVC(kernel='rbf', verbose=True, C=1.5, class_weight=weights_ee)\n",
    "svm_c_c = SVC(kernel='rbf', verbose=True, C=1.5, class_weight=weights_cc)\n",
    "\n",
    "# Binary SVM classifiers for each pair of classes\n",
    "svm_h_e = SVC(kernel='rbf', verbose=True, C=1.5, class_weight=weights_he)\n",
    "svm_e_c = SVC(kernel='rbf', verbose=True, C=1.5, class_weight=weights_ec)\n",
    "svm_c_h = SVC(kernel='rbf', verbose=True, C=1.5, class_weight=weights_ch)\n",
    "\n",
    "# Fit the SVM classifiers\n",
    "svm_h_h.fit(X_train_11_reshaped, h_not_h)\n",
    "svm_e_e.fit(X_train_9_reshaped, e_not_e)\n",
    "svm_c_c.fit(X_train_7_reshaped, c_not_c)\n",
    "svm_h_e.fit(X_train_9_reshaped, h_not_e)\n",
    "svm_e_c.fit(X_train_5_reshaped, e_not_c)\n",
    "svm_c_h.fit(X_train_9_reshaped, c_not_h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 347,
   "metadata": {},
   "outputs": [],
   "source": [
    "h_h_scores = svm_h_h.decision_function(X_train_11_reshaped)\n",
    "e_e_scores = svm_e_e.decision_function(X_train_9_reshaped)\n",
    "c_c_scores = svm_c_c.decision_function(X_train_7_reshaped)\n",
    "h_e_scores = svm_h_e.decision_function(X_train_9_reshaped)\n",
    "e_c_scores = svm_e_c.decision_function(X_train_5_reshaped)\n",
    "c_h_scores = svm_c_h.decision_function(X_train_9_reshaped)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 348,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_svm_max_d(c_c_scores, e_e_scores, h_h_scores):\n",
    "  predicted_classes = np.argmax([c_c_scores, e_e_scores, h_h_scores], axis=0)\n",
    "  return predicted_classes\n",
    "\n",
    "combined_predictions_max_d = predict_svm_max_d(c_c_scores, e_e_scores, h_h_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 349,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_svm_tree1(h_h_scores, e_c_scores):\n",
    "  # Classify based on first SVM (H/not H)\n",
    "    predicted_classes = []\n",
    "    for i in range(len(h_h_scores)):\n",
    "        if h_h_scores[i] > 0:\n",
    "            predicted_classes.append(2)\n",
    "        elif e_c_scores[i,2] > e_c_scores[i,0]:\n",
    "            predicted_classes.append(1)\n",
    "        else:\n",
    "            predicted_classes.append(0)\n",
    "    return np.array(predicted_classes)\n",
    "\n",
    "combined_predictions_tree1 = predict_svm_tree1(h_h_scores, e_c_scores)\n",
    "\n",
    "def predict_svm_tree2(e_e_scores, c_h_scores):\n",
    "  # Classify based on first SVM (E/not E)\n",
    "    predicted_classes = []\n",
    "    for i in range(len(e_e_scores)):\n",
    "        if e_e_scores[i] > 0:\n",
    "            predicted_classes.append(1)\n",
    "        elif c_h_scores[i,2] > c_h_scores[i,0]:\n",
    "            predicted_classes.append(0)\n",
    "        else:\n",
    "            predicted_classes.append(2)\n",
    "    return np.array(predicted_classes)\n",
    "\n",
    "def predict_svm_tree3(c_c_scores, h_e_scores):\n",
    "  # Classify based on first SVM (C/not C)\n",
    "    predicted_classes = []\n",
    "    for i in range(len(c_c_scores)):\n",
    "        if c_c_scores[i] > 0:\n",
    "            predicted_classes.append(0)\n",
    "        elif h_e_scores[i,2] > h_e_scores[i,0]:\n",
    "            predicted_classes.append(2)\n",
    "        else:\n",
    "            predicted_classes.append(1)\n",
    "    return np.array(predicted_classes)\n",
    "\n",
    "combined_predictions_tree1 = predict_svm_tree1(h_h_scores, e_c_scores)\n",
    "combined_predictions_tree2 = predict_svm_tree2(e_e_scores, c_h_scores)\n",
    "combined_predictions_tree3 = predict_svm_tree3(c_c_scores, h_e_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 350,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_svm_vote(X_train_11, X_train_9, X_train_7, X_train_5):\n",
    "    # Predictions from all six binary classifiers\n",
    "    all_votes = np.vstack([\n",
    "        svm_h_h.predict(X_train_11),\n",
    "        svm_e_e.predict(X_train_9),\n",
    "        svm_c_c.predict(X_train_7),\n",
    "        svm_h_e.predict(X_train_9),\n",
    "        svm_e_c.predict(X_train_5),\n",
    "        svm_c_h.predict(X_train_9)\n",
    "    ]).T\n",
    "\n",
    "    # Counting votes using NumPy operations\n",
    "    votes = np.zeros((len(all_votes), 3), dtype=int)\n",
    "    votes[:, 2] += np.sum(all_votes[:, [0, 3, 5]], axis=1)\n",
    "    votes[:, 1] += np.sum(all_votes[:, [1, 3, 4]], axis=1)\n",
    "    votes[:, 0] += np.sum(all_votes[:, [2, 4, 5]], axis=1)\n",
    "\n",
    "    # Choosing the class with the maximum votes\n",
    "    predictions = np.argmax(votes, axis=1)\n",
    "\n",
    "    # Handling ties\n",
    "    max_votes = np.max(votes, axis=1)\n",
    "    tie_mask = (votes == max_votes[:, None])\n",
    "    tie_counts = np.sum(tie_mask, axis=1)\n",
    "    predictions[tie_counts > 1] = 0  # Assign class 0 to ties\n",
    "\n",
    "    return predictions\n",
    "\n",
    "\n",
    "combined_predictions_vote = predict_svm_vote(X_train_11_reshaped, X_train_9_reshaped, X_train_7_reshaped, X_train_5_reshaped)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 387,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\willi\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\src\\layers\\convolutional\\base_conv.py:99: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m566/566\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - accuracy: 0.4961 - loss: 1.1146 - val_accuracy: 0.5858 - val_loss: 0.9141\n",
      "Epoch 2/100\n",
      "\u001b[1m566/566\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.5712 - loss: 0.9201 - val_accuracy: 0.6045 - val_loss: 0.8617\n",
      "Epoch 3/100\n",
      "\u001b[1m566/566\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.5900 - loss: 0.8674 - val_accuracy: 0.6213 - val_loss: 0.8377\n",
      "Epoch 4/100\n",
      "\u001b[1m566/566\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.6295 - loss: 0.8185 - val_accuracy: 0.6310 - val_loss: 0.8295\n",
      "Epoch 5/100\n",
      "\u001b[1m566/566\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.6379 - loss: 0.8020 - val_accuracy: 0.6295 - val_loss: 0.8266\n",
      "Epoch 6/100\n",
      "\u001b[1m566/566\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.6477 - loss: 0.7827 - val_accuracy: 0.6344 - val_loss: 0.8364\n",
      "Epoch 7/100\n",
      "\u001b[1m566/566\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.6656 - loss: 0.7582 - val_accuracy: 0.6335 - val_loss: 0.8266\n",
      "Epoch 8/100\n",
      "\u001b[1m566/566\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.6734 - loss: 0.7351 - val_accuracy: 0.6378 - val_loss: 0.8283\n",
      "Epoch 9/100\n",
      "\u001b[1m566/566\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.6816 - loss: 0.7204 - val_accuracy: 0.6392 - val_loss: 0.8667\n",
      "Epoch 10/100\n",
      "\u001b[1m566/566\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.6911 - loss: 0.7047 - val_accuracy: 0.6352 - val_loss: 0.8645\n",
      "Epoch 11/100\n",
      "\u001b[1m566/566\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.6978 - loss: 0.6929 - val_accuracy: 0.6264 - val_loss: 0.8566\n",
      "Epoch 11: early stopping\n",
      "Restoring model weights from the end of the best epoch: 5.\n",
      "\u001b[1m566/566\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step\n",
      "Total Accuracy: 0.6295454545454545\n",
      "Class Accuracies: {0: 0.7789911596463859, 1: 0.37967914438502676, 2: 0.5111896348645465}\n",
      "Epoch 1/100\n",
      "\u001b[1m566/566\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - accuracy: 0.4986 - loss: 1.0935 - val_accuracy: 0.5048 - val_loss: 0.9879\n",
      "Epoch 2/100\n",
      "\u001b[1m566/566\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.5762 - loss: 0.9101 - val_accuracy: 0.6023 - val_loss: 0.8728\n",
      "Epoch 3/100\n",
      "\u001b[1m566/566\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.6047 - loss: 0.8545 - val_accuracy: 0.5866 - val_loss: 0.8733\n",
      "Epoch 4/100\n",
      "\u001b[1m566/566\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.6232 - loss: 0.8227 - val_accuracy: 0.5926 - val_loss: 0.8746\n",
      "Epoch 5/100\n",
      "\u001b[1m566/566\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.6398 - loss: 0.7993 - val_accuracy: 0.6156 - val_loss: 0.8874\n",
      "Epoch 6/100\n",
      "\u001b[1m566/566\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.6539 - loss: 0.7730 - val_accuracy: 0.6128 - val_loss: 0.8892\n",
      "Epoch 7/100\n",
      "\u001b[1m566/566\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.6713 - loss: 0.7486 - val_accuracy: 0.6082 - val_loss: 0.9420\n",
      "Epoch 8/100\n",
      "\u001b[1m566/566\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.6840 - loss: 0.7236 - val_accuracy: 0.6440 - val_loss: 0.8773\n",
      "Epoch 8: early stopping\n",
      "Restoring model weights from the end of the best epoch: 2.\n",
      "\u001b[1m566/566\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step\n",
      "Total Accuracy: 0.6022727272727273\n",
      "Class Accuracies: {0: 0.8081123244929798, 1: 0.11096256684491979, 2: 0.568904593639576}\n",
      "Epoch 1/100\n",
      "\u001b[1m566/566\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - accuracy: 0.5091 - loss: 1.0547 - val_accuracy: 0.5946 - val_loss: 0.9052\n",
      "Epoch 2/100\n",
      "\u001b[1m566/566\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.5813 - loss: 0.9041 - val_accuracy: 0.6165 - val_loss: 0.8655\n",
      "Epoch 3/100\n",
      "\u001b[1m566/566\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.6090 - loss: 0.8512 - val_accuracy: 0.6287 - val_loss: 0.8415\n",
      "Epoch 4/100\n",
      "\u001b[1m566/566\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.6283 - loss: 0.8253 - val_accuracy: 0.6369 - val_loss: 0.8360\n",
      "Epoch 5/100\n",
      "\u001b[1m566/566\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.6445 - loss: 0.7962 - val_accuracy: 0.6477 - val_loss: 0.8306\n",
      "Epoch 6/100\n",
      "\u001b[1m566/566\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.6572 - loss: 0.7746 - val_accuracy: 0.6398 - val_loss: 0.8325\n",
      "Epoch 7/100\n",
      "\u001b[1m566/566\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.6662 - loss: 0.7430 - val_accuracy: 0.6304 - val_loss: 0.8712\n",
      "Epoch 8/100\n",
      "\u001b[1m566/566\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.6828 - loss: 0.7208 - val_accuracy: 0.6327 - val_loss: 0.8767\n",
      "Epoch 9/100\n",
      "\u001b[1m566/566\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.6866 - loss: 0.7168 - val_accuracy: 0.6369 - val_loss: 0.8616\n",
      "Epoch 10/100\n",
      "\u001b[1m566/566\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.6963 - loss: 0.7009 - val_accuracy: 0.6324 - val_loss: 0.8777\n",
      "Epoch 11/100\n",
      "\u001b[1m566/566\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.6966 - loss: 0.6993 - val_accuracy: 0.6440 - val_loss: 0.8833\n",
      "Epoch 11: early stopping\n",
      "Restoring model weights from the end of the best epoch: 5.\n",
      "\u001b[1m566/566\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step\n",
      "Total Accuracy: 0.6477272727272727\n",
      "Class Accuracies: {0: 0.8413936557462298, 1: 0.31283422459893045, 2: 0.5041224970553593}\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Conv1D(filters=32, kernel_size=5, activation='relu', padding='same', input_shape=(13,20)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Conv1D(filters=64, kernel_size=3, activation='relu', padding='same'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Conv1D(filters=128, kernel_size=3, activation='relu', padding='same'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dense(3, activation='softmax'))\n",
    "\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=6, verbose=1, restore_best_weights=True)\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(X_train_13, y_train, epochs=100, batch_size=32, validation_data=(X_test_13, y_test),  callbacks=[early_stopping])\n",
    "\n",
    "NN_pred = model.predict(X_train_13)\n",
    "combined_predictions_NN = np.argmax(NN_pred, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 355,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nn_inputs = np.column_stack((h_h_scores, e_e_scores, c_c_scores, h_e_scores, e_c_scores, c_h_scores))\n",
    "# # nn_inputs = np.column_stack((h_e_scores, e_c_scores, c_h_scores))\n",
    "# # nn_inputs = np.column_stack((h_h_scores, e_e_scores, c_c_scores))\n",
    "\n",
    "# # model = tf.keras.Sequential([\n",
    "# #     tf.keras.layers.Dense(20, activation='relu'),\n",
    "# #     tf.keras.layers.Dense(3, activation='softmax')\n",
    "# # ])\n",
    "\n",
    "# model = Sequential([\n",
    "#     # Input(shape=(13, 21)),\n",
    "#     # Flatten(),\n",
    "#     Dense(units=27, activation='relu'),\n",
    "#     # LSTM(units=273, activation='relu'),\n",
    "#     Dense(units=3, activation='softmax')\n",
    "# ])\n",
    "\n",
    "# model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "# model.fit(nn_inputs, y_train, epochs=10, batch_size=32, verbose=1)\n",
    "\n",
    "# NN_pred = model.predict(nn_inputs)\n",
    "\n",
    "# combined_predictions_NN = np.argmax(NN_pred, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 356,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_weightings(accuracies):\n",
    "    total_accuracy = sum(accuracies.values())\n",
    "    weightings = {classifier: accuracy / total_accuracy for classifier, accuracy in accuracies.items()}\n",
    "    return weightings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 388,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max_D\n",
      "Total Accuracy: 0.9450980392156862\n",
      "Class Accuracies: {0: 0.91335630320227, 1: 0.977997799779978, 2: 0.9871767007172354}\n",
      "\n",
      "Tree1\n",
      "Total Accuracy: 0.8821872410936206\n",
      "Class Accuracies: {0: 0.824787190920146, 1: 0.8938393839383938, 2: 0.9960878069984785}\n",
      "\n",
      "Tree2\n",
      "Total Accuracy: 0.9182546257939795\n",
      "Class Accuracies: {0: 0.8801175516822051, 1: 0.9958745874587459, 2: 0.9387089763094979}\n",
      "\n",
      "Tree3\n",
      "Total Accuracy: 0.8982049157691245\n",
      "Class Accuracies: {0: 0.8858937981353872, 1: 0.9062156215621562, 2: 0.9182786350793306}\n",
      "\n",
      "Vote\n",
      "Total Accuracy: 0.9122341894504281\n",
      "Class Accuracies: {0: 0.9116335630320227, 1: 0.9042904290429042, 2: 0.9198000434688112}\n",
      "\n",
      "NN\n",
      "Total Accuracy: 0.6950013808340237\n",
      "Class Accuracies: {0: 0.8298540737738144, 1: 0.3943894389438944, 2: 0.6433384046946315}\n"
     ]
    }
   ],
   "source": [
    "print(\"Max_D\")\n",
    "maxd, maxd_class = calculate_accuracy(y_train, combined_predictions_max_d)\n",
    "print(\"Total Accuracy:\", maxd)\n",
    "print(\"Class Accuracies:\", maxd_class)\n",
    "print(\"\\nTree1\")\n",
    "tree1, tree1_class = calculate_accuracy(y_train, combined_predictions_tree1)\n",
    "print(\"Total Accuracy:\", tree1)\n",
    "print(\"Class Accuracies:\", tree1_class)\n",
    "print(\"\\nTree2\")\n",
    "tree2, tree2_class = calculate_accuracy(y_train, combined_predictions_tree2)\n",
    "print(\"Total Accuracy:\", tree2)\n",
    "print(\"Class Accuracies:\", tree2_class)\n",
    "print(\"\\nTree3\")\n",
    "tree3, tree3_class = calculate_accuracy(y_train, combined_predictions_tree3)\n",
    "print(\"Total Accuracy:\", tree3)\n",
    "print(\"Class Accuracies:\", tree3_class)\n",
    "print(\"\\nVote\")\n",
    "vote, vote_class = calculate_accuracy(y_train, combined_predictions_vote)\n",
    "print(\"Total Accuracy:\", vote)\n",
    "print(\"Class Accuracies:\", vote_class)\n",
    "print(\"\\nNN\")\n",
    "nn, nn_class = calculate_accuracy(y_train, combined_predictions_NN)\n",
    "print(\"Total Accuracy:\", nn)\n",
    "print(\"Class Accuracies:\", nn_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 358,
   "metadata": {},
   "outputs": [],
   "source": [
    "def svm_jury(combined_predictions_max_d, combined_predictions_tree1,\n",
    "             combined_predictions_tree2, combined_predictions_tree3, combined_predictions_vote, combined_predictions_NN, accuracies, class_accuracies):\n",
    "    \n",
    "    assert combined_predictions_max_d.shape == combined_predictions_vote.shape == combined_predictions_tree1.shape == \\\n",
    "           combined_predictions_tree2.shape == combined_predictions_tree3.shape == combined_predictions_NN.shape, \\\n",
    "           \"All predictions must have the same shape.\"\n",
    "    \n",
    "    num_samples = combined_predictions_max_d.shape[0]\n",
    "    \n",
    "    jury_predictions = np.zeros((num_samples,3))\n",
    "    \n",
    "    for i in range(num_samples):\n",
    "        # Count the number of votes for each class (C, E, H)\n",
    "        votes = [0, 0, 0]\n",
    "        votes[combined_predictions_max_d[i]] += accuracies['Max_D'] * class_accuracies['Max_D'][combined_predictions_max_d[i]]\n",
    "        votes[combined_predictions_tree1[i]] += accuracies['Tree1'] * class_accuracies['Tree1'][combined_predictions_tree1[i]]\n",
    "        votes[combined_predictions_tree2[i]] += accuracies['Tree2'] * class_accuracies['Tree2'][combined_predictions_tree2[i]]\n",
    "        votes[combined_predictions_tree3[i]] += accuracies['Tree3'] * class_accuracies['Tree3'][combined_predictions_tree3[i]]\n",
    "        votes[combined_predictions_vote[i]] += accuracies['Vote'] * class_accuracies['Vote'][combined_predictions_vote[i]]\n",
    "        votes[combined_predictions_NN[i]] += accuracies['NN'] * class_accuracies['NN'][combined_predictions_NN[i]]\n",
    "\n",
    "        # votes[combined_predictions_max_d[i]] += class_accuracies['Max_D'][combined_predictions_max_d[i]]\n",
    "        # votes[combined_predictions_tree1[i]] += class_accuracies['Tree1'][combined_predictions_tree1[i]]\n",
    "        # votes[combined_predictions_tree2[i]] += class_accuracies['Tree2'][combined_predictions_tree2[i]]\n",
    "        # votes[combined_predictions_tree3[i]] += class_accuracies['Tree3'][combined_predictions_tree3[i]]\n",
    "        # votes[combined_predictions_vote[i]] += class_accuracies['Vote'][combined_predictions_vote[i]]\n",
    "        # votes[combined_predictions_NN[i]] += class_accuracies['NN'][combined_predictions_NN[i]]\n",
    "\n",
    "        # votes[combined_predictions_max_d[i]] += accuracies['Max_D']\n",
    "        # votes[combined_predictions_tree1[i]] += accuracies['Tree1']\n",
    "        # votes[combined_predictions_tree2[i]] += accuracies['Tree2']\n",
    "        # votes[combined_predictions_tree3[i]] += accuracies['Tree3']\n",
    "        # votes[combined_predictions_vote[i]] += accuracies['Vote']\n",
    "        # votes[combined_predictions_NN[i]] += accuracies['NN']\n",
    "\n",
    "        # votes[combined_predictions_max_d[i]] += 1\n",
    "        # votes[combined_predictions_tree1[i]] += 1\n",
    "        # votes[combined_predictions_tree2[i]] += 1\n",
    "        # votes[combined_predictions_tree3[i]] += 1\n",
    "        # votes[combined_predictions_vote[i]] += 1\n",
    "        # votes[combined_predictions_NN[i]] += 1\n",
    "\n",
    "        jury_predictions[i] = np.array(votes)\n",
    "\n",
    "    return jury_predictions\n",
    "\n",
    "accuracies = {\n",
    "    'Max_D': maxd,\n",
    "    'Tree1': tree1,\n",
    "    'Tree2': tree2,\n",
    "    'Tree3': tree3,\n",
    "    'Vote': vote,\n",
    "    'NN': nn,\n",
    "}\n",
    "\n",
    "class_accuracies = {\n",
    "    'Max_D': maxd_class,\n",
    "    'Tree1': tree1_class,\n",
    "    'Tree2': tree2_class,\n",
    "    'Tree3': tree3_class,\n",
    "    'Vote': vote_class,\n",
    "    'NN': nn_class,\n",
    "}\n",
    "\n",
    "for key, inner_dict in class_accuracies.items():\n",
    "    class_accuracies[key][0] *= 0.7\n",
    "\n",
    "bruh = svm_jury(combined_predictions_max_d, combined_predictions_vote, combined_predictions_tree1, combined_predictions_tree2, combined_predictions_tree3, combined_predictions_NN, accuracies, class_accuracies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 359,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_result = np.argmax(bruh, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 360,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Accuracy: 0.9249378624689313\n",
      "Class Accuracies: {0: 0.8881232265910012, 1: 0.9537953795379538, 2: 0.9810910671593132}\n"
     ]
    }
   ],
   "source": [
    "train_total_accuracy, train_class_accuracy = calculate_accuracy(y_train, train_result)\n",
    "print(\"Total Accuracy:\", train_total_accuracy)\n",
    "print(\"Class Accuracies:\", train_class_accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 361,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_13_reshaped = X_test_13.reshape(X_test_13.shape[0], -1)\n",
    "\n",
    "X_test_11_reshaped = X_test_11.reshape(X_test_11.shape[0], -1)\n",
    "X_test_9_reshaped = X_test_9.reshape(X_test_9.shape[0], -1)\n",
    "X_test_7_reshaped = X_test_7.reshape(X_test_7.shape[0], -1)\n",
    "X_test_5_reshaped = X_test_5.reshape(X_test_5.shape[0], -1)\n",
    "\n",
    "h_h_scores_test = svm_h_h.decision_function(X_test_11_reshaped)\n",
    "e_e_scores_test = svm_e_e.decision_function(X_test_9_reshaped)\n",
    "c_c_scores_test = svm_c_c.decision_function(X_test_7_reshaped)\n",
    "h_e_scores_test = svm_h_e.decision_function(X_test_9_reshaped)\n",
    "e_c_scores_test = svm_e_c.decision_function(X_test_5_reshaped)\n",
    "c_h_scores_test = svm_c_h.decision_function(X_test_9_reshaped)\n",
    "\n",
    "combined_predictions_max_d_test = predict_svm_max_d(c_c_scores_test, e_e_scores_test, h_h_scores_test)\n",
    "combined_predictions_tree1_test = predict_svm_tree1(h_h_scores_test, e_c_scores_test)\n",
    "combined_predictions_tree2_test = predict_svm_tree2(e_e_scores_test, c_h_scores_test)\n",
    "combined_predictions_tree3_test = predict_svm_tree3(c_c_scores_test, h_e_scores_test)\n",
    "combined_predictions_vote_test = predict_svm_vote(X_test_11_reshaped, X_test_9_reshaped, X_test_7_reshaped, X_test_5_reshaped)\n",
    "\n",
    "# nn_inputs_test = np.column_stack((h_h_scores_test, e_e_scores_test, c_c_scores_test, h_e_scores_test, e_c_scores_test, c_h_scores_test))\n",
    "# # nn_inputs_test = np.column_stack((h_e_scores_test, e_c_scores_test, c_h_scores_test))\n",
    "# # nn_inputs_test = np.column_stack((h_h_scores_test, e_e_scores_test, c_c_scores_test))\n",
    "# NN_pred_test = model.predict(nn_inputs_test)\n",
    "# combined_predictions_NN_test = np.argmax(NN_pred_test, axis=1)\n",
    "\n",
    "NN_pred_test = model.predict(X_test_13)\n",
    "combined_predictions_NN_test = np.argmax(NN_pred_test, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 389,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max_D\n",
      "Total Accuracy: 0.5988636363636364\n",
      "Class Accuracies: {0: 0.719188767550702, 1: 0.42513368983957217, 2: 0.4793875147232038}\n",
      "MCC for class coil: 0.3707619591223551\n",
      "MCC for class β-sheet: 0.2705039085040551\n",
      "MCC for class α-helix: 0.32199134485576164\n",
      "\n",
      "Tree1\n",
      "Total Accuracy: 0.5900568181818182\n",
      "Class Accuracies: {0: 0.6692667706708268, 1: 0.47192513368983957, 2: 0.5147232037691402}\n",
      "MCC for class coil: 0.3621438622013262\n",
      "MCC for class β-sheet: 0.2605310085102478\n",
      "MCC for class α-helix: 0.3589190876314922\n",
      "\n",
      "Tree2\n",
      "Total Accuracy: 0.5971590909090909\n",
      "Class Accuracies: {0: 0.6983879355174207, 1: 0.42780748663101603, 2: 0.5170789163722026}\n",
      "MCC for class coil: 0.36875277271724705\n",
      "MCC for class β-sheet: 0.27788187236321465\n",
      "MCC for class α-helix: 0.3314932418626386\n",
      "\n",
      "Tree3\n",
      "Total Accuracy: 0.5954545454545455\n",
      "Class Accuracies: {0: 0.6952678107124285, 1: 0.4385026737967914, 2: 0.5076560659599529}\n",
      "MCC for class coil: 0.3698547018642283\n",
      "MCC for class β-sheet: 0.2825080133973469\n",
      "MCC for class α-helix: 0.32177421607809104\n",
      "\n",
      "Vote\n",
      "Total Accuracy: 0.596875\n",
      "Class Accuracies: {0: 0.7441497659906396, 1: 0.410427807486631, 2: 0.4275618374558304}\n",
      "MCC for class coil: 0.33782887347264196\n",
      "MCC for class β-sheet: 0.2621343135781201\n",
      "MCC for class α-helix: 0.31903243213455085\n",
      "\n",
      "NN\n",
      "Total Accuracy: 0.6477272727272727\n",
      "Class Accuracies: {0: 0.8413936557462298, 1: 0.31283422459893045, 2: 0.5041224970553593}\n",
      "MCC for class coil: 0.4168677365510408\n",
      "MCC for class β-sheet: 0.29138840998792354\n",
      "MCC for class α-helix: 0.40309116556431496\n"
     ]
    }
   ],
   "source": [
    "print(\"Max_D\")\n",
    "maxd_test, maxd_class_test = calculate_accuracy(y_test, combined_predictions_max_d_test)\n",
    "print(\"Total Accuracy:\", maxd_test)\n",
    "print(\"Class Accuracies:\", maxd_class_test)\n",
    "calculate_correlation_coefficients(y_test, combined_predictions_max_d_test)\n",
    "print(\"\\nTree1\")\n",
    "tree1_test, tree1_class_test = calculate_accuracy(y_test, combined_predictions_tree1_test)\n",
    "print(\"Total Accuracy:\", tree1_test)\n",
    "print(\"Class Accuracies:\", tree1_class_test)\n",
    "calculate_correlation_coefficients(y_test, combined_predictions_tree1_test)\n",
    "print(\"\\nTree2\")\n",
    "tree2_test, tree2_class_test = calculate_accuracy(y_test, combined_predictions_tree2_test)\n",
    "print(\"Total Accuracy:\", tree2_test)\n",
    "print(\"Class Accuracies:\", tree2_class_test)\n",
    "calculate_correlation_coefficients(y_test, combined_predictions_tree2_test)\n",
    "print(\"\\nTree3\")\n",
    "tree3_test, tree3_class_test = calculate_accuracy(y_test, combined_predictions_tree3_test)\n",
    "print(\"Total Accuracy:\", tree3_test)\n",
    "print(\"Class Accuracies:\", tree3_class_test)\n",
    "calculate_correlation_coefficients(y_test, combined_predictions_tree3_test)\n",
    "print(\"\\nVote\")\n",
    "vote_test, vote_class_test = calculate_accuracy(y_test, combined_predictions_vote_test)\n",
    "print(\"Total Accuracy:\", vote_test)\n",
    "print(\"Class Accuracies:\", vote_class_test)\n",
    "calculate_correlation_coefficients(y_test, combined_predictions_vote_test)\n",
    "print(\"\\nNN\")\n",
    "nn_test, nn_class_test = calculate_accuracy(y_test, combined_predictions_NN_test)\n",
    "print(\"Total Accuracy:\", nn_test)\n",
    "print(\"Class Accuracies:\", nn_class_test)\n",
    "calculate_correlation_coefficients(y_test, combined_predictions_NN_test)\n",
    "\n",
    "accuracies_test = {\n",
    "    'Max_D': maxd_test,\n",
    "    'Tree1': tree1_test,\n",
    "    'Tree2': tree2_test,\n",
    "    'Tree3': tree3_test,\n",
    "    'Vote': vote_test,\n",
    "    'NN': nn_test,\n",
    "}\n",
    "\n",
    "class_accuracies_test = {\n",
    "    'Max_D': maxd_class_test,\n",
    "    'Tree1': tree1_class_test,\n",
    "    'Tree2': tree2_class_test,\n",
    "    'Tree3': tree3_class_test,\n",
    "    'Vote': vote_class_test,\n",
    "    'NN': nn_class_test,\n",
    "}\n",
    "\n",
    "bruh_test = svm_jury(combined_predictions_max_d_test, combined_predictions_tree1_test, combined_predictions_tree2_test, combined_predictions_tree3_test, combined_predictions_vote_test, combined_predictions_NN_test, accuracies_test, class_accuracies_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 395,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Accuracy: 0.6210227272727272\n",
      "Class Accuracies: {0: 0.7753510140405616, 1: 0.3783422459893048, 2: 0.48527679623085984}\n"
     ]
    }
   ],
   "source": [
    "test_result = np.argmax(bruh_test, axis=1)\n",
    "test_total_accuracy, test_class_accuracy = calculate_accuracy(y_test, test_result)\n",
    "print(\"Total Accuracy:\", test_total_accuracy)\n",
    "print(\"Class Accuracies:\", test_class_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 391,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MCC for class coil: 0.3797932455727784\n",
      "MCC for class β-sheet: 0.28198199176172734\n",
      "MCC for class α-helix: 0.3596039716401946\n"
     ]
    }
   ],
   "source": [
    "calculate_correlation_coefficients(y_test, test_result)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
